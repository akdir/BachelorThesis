\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{avtest}
\citation{ist}
\citation{arntz_2016}
\citation{DBLP:journals/corr/abs-1810-04805}
\citation{BooksCorpus}
\citation{ColBERT}
\citation{Sanh2019DistilBERTAD}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{2}{Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminaries}{5}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{preliminaries}{{2}{5}{Preliminaries}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Botnets}{5}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Domain Generation Algorithm}{6}{section.2.2}\protected@file@percent }
\citation{Unsupervised}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Machine Learning}{7}{section.2.3}\protected@file@percent }
\citation{Gradient_Descent}
\citation{Dying_ReLU}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Neural Networks}{8}{section.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.5}Activation Functions}{8}{section.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.1}ReLU Activation Function}{8}{subsection.2.5.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces \href  {https://cdn-images-1.medium.com/max/1600/1*DfMRHwxY1gyyDmrIAd-gjQ.png}{ReLU activation function} }}{9}{figure.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.2}Sigmoid Activation Function}{9}{subsection.2.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces \href  {https://www.researchgate.net/profile/Stefano_Romanazzi2/publication/325226633/figure/download/fig7/AS:627667619545098@1526659030915/Plot-of-the-sigmoid-function.png}{Sigmoid activation function} }}{9}{figure.2.2}\protected@file@percent }
\citation{Tan_h}
\citation{DBLP:journals/corr/HeZRS15}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5.3}Tanh Activation Function}{10}{subsection.2.5.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces \href  {https://qph.fs.quoracdn.net/main-qimg-8aa9a4ad89a6a58b86aba86b136261f9}{Tanh activation function} }}{10}{figure.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2.6}Recurrent Neural Networks}{10}{section.2.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces \href  {https://cdn-images-1.medium.com/max/1600/1*NKhwsOYNUT5xU7Pyf6Znhg.png}{Recurrent Neural Network (RNN) illustration} }}{11}{figure.2.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.1}Vanishing Gradient Problem}{11}{subsection.2.6.1}\protected@file@percent }
\newlabel{vgp}{{2.6.1}{11}{Vanishing Gradient Problem}{subsection.2.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.6.2}LSTM}{11}{subsection.2.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces \href  {https://www.researchgate.net/profile/Chinthakunta-Manjunath/publication/347840605/figure/fig1/AS:972281069182976@1608821279006/The-structure-of-the-LSTM-unit.ppm}{Long short-term memory network (LSTM) illustration} }}{12}{figure.2.5}\protected@file@percent }
\citation{Transformers}
\citation{sts}
\citation{ffn}
\@writefile{toc}{\contentsline {section}{\numberline {2.7}Transformers}{13}{section.2.7}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces \href  {https://miro.medium.com/max/1812/1*57LYNxwBGcCFFhkOCSnJ3g.png}{The Transformer model architecture} }}{14}{figure.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.7.1}BERT}{14}{subsection.2.7.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces \href  {https://media.arxiv-vanity.com/render-output/5396393/MLM_LS.png}{BERT for masked model architecture} }}{15}{figure.2.7}\protected@file@percent }
\citation{maiya2020ktrain}
\citation{chollet2015keras}
\citation{sklearn_api}
\citation{Tranco}
\citation{Antonakakis}
\citation{Lison}
\citation{Highnam}
\citation{TRAN20182401}
\citation{Tranco}
\citation{UMUDGA}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Research}{17}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{research}{{3}{17}{Research}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}System Architecture}{17}{section.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Datasets}{17}{section.3.2}\protected@file@percent }
\citation{Sanh2019DistilBERTAD}
\citation{ColBERT}
\citation{WordPiece}
\citation{Learning_Rate}
\citation{cycle_learning_rate}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}DistilBERT Detector}{18}{section.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Learning Rate}{18}{subsection.3.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces DistilBERT LR Range test result}}{20}{figure.3.1}\protected@file@percent }
\newlabel{figure_lr}{{3.1}{20}{DistilBERT LR Range test result}{figure.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Metrics For Validation}{20}{section.3.4}\protected@file@percent }
\citation{Highnam}
\citation{Woodbridge}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Experiment}{21}{section.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Calculating our training performance: loss of our model in each epoch for our train and validation dataset}}{22}{figure.3.2}\protected@file@percent }
\newlabel{figure_model}{{3.2}{22}{Calculating our training performance: loss of our model in each epoch for our train and validation dataset}{figure.3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces Results of our DistilBERT model, expressed in Precision, Recall and F1-score}}{23}{table.3.1}\protected@file@percent }
\newlabel{general_results}{{3.1}{23}{Results of our DistilBERT model, expressed in Precision, Recall and F1-score}{table.3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3.2}{\ignorespaces Results of our DistilBERT model on each distinct DGA family, expressed in Precision, Recall and F1-score. The }}{24}{table.3.2}\protected@file@percent }
\newlabel{specific_results}{{3.2}{24}{Results of our DistilBERT model on each distinct DGA family, expressed in Precision, Recall and F1-score. The}{table.3.2}{}}
\citation{Chang_Lin}
\citation{Zhou2013DGABasedBD}
\citation{Antonakakis}
\citation{Woodbridge}
\citation{Anderson}
\citation{TRAN20182401}
\citation{Chen}
\citation{Lison}
\citation{Koh}
\citation{Highnam}
\citation{Koh}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Related Work}{25}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{relatedwork}{{4}{25}{Related Work}{chapter.4}{}}
\citation{Sanh2019DistilBERTAD}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Contribution}{26}{section.4.1}\protected@file@percent }
\citation{Sanh2019DistilBERTAD}
\bibstyle{plain}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions}{27}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusions}{{5}{27}{Conclusions}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Acknowledgement}{27}{section.5.1}\protected@file@percent }
\bibcite{Anderson}{1}
\bibcite{sts}{2}
\bibcite{ColBERT}{3}
\bibcite{Antonakakis}{4}
\bibcite{arntz_2016}{5}
\bibcite{avtest}{6}
\bibcite{sklearn_api}{7}
\bibcite{Chang_Lin}{8}
\bibcite{Chen}{9}
\bibcite{chollet2015keras}{10}
\bibcite{DBLP:journals/corr/abs-1810-04805}{11}
\bibcite{DBLP:journals/corr/HeZRS15}{12}
\bibcite{Highnam}{13}
\bibcite{Koh}{14}
\bibcite{Unsupervised}{15}
\bibcite{Gradient_Descent}{16}
\bibcite{Lison}{17}
\bibcite{Dying_ReLU}{18}
\bibcite{maiya2020ktrain}{19}
\bibcite{Tranco}{20}
\bibcite{Sanh2019DistilBERTAD}{21}
\bibcite{ffn}{22}
\bibcite{Learning_Rate}{23}
\bibcite{cycle_learning_rate}{24}
\bibcite{ist}{25}
\bibcite{TRAN20182401}{26}
\bibcite{Transformers}{27}
\bibcite{Woodbridge}{28}
\bibcite{WordPiece}{29}
\bibcite{Tan_h}{30}
\bibcite{UMUDGA}{31}
\bibcite{Zhou2013DGABasedBD}{32}
\bibcite{BooksCorpus}{33}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Appendix}{32}{appendix.A}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{appendix}{{A}{32}{Appendix}{appendix.A}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Source Code DistilBERT Model}{32}{section.A.1}\protected@file@percent }
\gdef \@abspage@last{39}
